{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Finetune ProteinBERT for ASM classification\n",
    "### 0. (OPTIONAL) Prepare datasets from fasta for binary classification"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import random\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "FOLD_NO = \"6\"\n",
    "\n",
    "\n",
    "def read_fasta(file_path, label):\n",
    "    \"\"\"Read a FASTA file and return a list of (sequence, label) tuples.\"\"\"\n",
    "    sequences = []\n",
    "    with open(file_path, \"r\") as fasta_file:\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            sequences.append((str(record.seq), label))\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def combine_and_shuffle(sequences1, sequences2):\n",
    "    \"\"\"Combine two lists of sequences, shuffle them, and return a DataFrame.\"\"\"\n",
    "    combined = sequences1 + sequences2\n",
    "    random.shuffle(combined)\n",
    "    return pd.DataFrame(combined, columns=['seq', 'label'])\n",
    "\n",
    "\n",
    "# Paths to the FASTA files\n",
    "path_negative_train = \"data(train+val)/negative/PB40/PB40_1z20_clu50_trn\" + FOLD_NO + \".fa\"\n",
    "path_positive_train = \"data(train+val)/positive/bass_motif/pad/bass_ctm_motif_trn\" + FOLD_NO + \".fa\"\n",
    "path_negative_val = \"data(train+val)/negative/PB40/PB40_1z20_clu50_val\" + FOLD_NO + \".fa\"\n",
    "path_positive_val = \"data(train+val)/positive/bass_motif/pad/bass_ctm_motif_val\" + FOLD_NO + \".fa\"\n",
    "path_negative_test = \"data(train+val)/negative/PB40/PB40_1z20_clu50_val\" + FOLD_NO + \".fa\"\n",
    "path_positive_test = \"data(train+val)/positive/bass_motif/bass_ntm_motif_test.fa\"\n",
    "\n",
    "# Read sequences and assign labels\n",
    "negative_sequences_train = read_fasta(path_negative_train, 0)\n",
    "positive_sequences_train = read_fasta(path_positive_train, 1)\n",
    "negative_sequences_val = read_fasta(path_negative_val, 0)\n",
    "positive_sequences_val = read_fasta(path_positive_val, 1)\n",
    "\n",
    "# Combine and shuffle datasets\n",
    "shuffled_data_train = combine_and_shuffle(negative_sequences_train, positive_sequences_train)\n",
    "shuffled_data_val = combine_and_shuffle(negative_sequences_val, positive_sequences_val)\n",
    "\n",
    "# Save to CSV\n",
    "shuffled_data_train.to_csv(\"data(train+val)/prepared/\" + FOLD_NO + \"/bass_pb40.train.csv\", index=False)\n",
    "shuffled_data_val.to_csv(\"data(train+val)/prepared/\" + FOLD_NO + \"/bass_pb40.val.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Verify configs and imports"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "BENCHMARK_NAME = 'bass_pb40'\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "# A local (non-global) binary output\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Finetune"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# for 6-fold cross-validation\n",
    "for i in range(1, 7):\n",
    "    model_no = i\n",
    "    BENCHMARKS_DIR = './data(train+val)/prepared/' + str(model_no)\n",
    "\n",
    "    train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "    valid_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.val.csv' % BENCHMARK_NAME)\n",
    "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "    valid_set = pd.read_csv(valid_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "    print(f'{len(train_set)} training set records, {len(valid_set)} validation set records.')\n",
    "\n",
    "    pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "    model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC,\n",
    "                                               pretraining_model_manipulation_function=get_model_with_hidden_layers_as_outputs,\n",
    "                                               dropout_rate=0.5)\n",
    "\n",
    "    training_callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.25, min_lr=1e-05, verbose=1),\n",
    "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "        keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, update_freq=100)\n",
    "    ]\n",
    "\n",
    "    finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'],\n",
    "             valid_set['label'],\n",
    "             seq_len=42, batch_size=64, max_epochs_per_stage=40, lr=1e-04, begin_with_frozen_pretrained_layers=True,\n",
    "             lr_with_frozen_pretrained_layers=1e-02, n_final_epochs=0, final_seq_len=1024, final_lr=5e-06,\n",
    "             callbacks=training_callbacks)\n",
    "\n",
    "    model = model_generator.create_model(seq_len=42)\n",
    "\n",
    "    model.save(\"./models/\" + str(model_no))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

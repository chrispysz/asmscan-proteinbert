{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T05:48:35.731636Z",
     "start_time": "2024-05-10T05:48:33.467520Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "BENCHMARK_NAME = 'bass_pb40'\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "# A local (non-global) binary output\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.3\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T06:27:31.560557Z",
     "start_time": "2024-05-10T05:48:37.585313Z"
    }
   },
   "source": [
    "# from numbers from 1 to 6\n",
    "for i in range(5, 7):\n",
    "    model_no = i\n",
    "    BENCHMARKS_DIR = './data//training/' + str(model_no)\n",
    "    # Loading the datasets\n",
    "    \n",
    "    train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "    valid_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.val.csv' % BENCHMARK_NAME)\n",
    "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "    valid_set = pd.read_csv(valid_set_file_path).dropna().drop_duplicates()\n",
    "    \n",
    "    print(f'{len(train_set)} training set records, {len(valid_set)} validation set records.')\n",
    "    \n",
    "    # Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "    \n",
    "    pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "    \n",
    "    # get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "    model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "            get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "    \n",
    "    training_callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "        keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True),\n",
    "        keras.callbacks.TensorBoard(log_dir = './logs', histogram_freq = 1, update_freq= 100)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "            seq_len = 42, batch_size = 64, max_epochs_per_stage = 40, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n",
    "            lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 0, final_seq_len = 1024, final_lr = 5e-06, callbacks = training_callbacks)\n",
    "    \n",
    "    \n",
    "    model=model_generator.create_model(seq_len=42)\n",
    "    \n",
    "    model.save(\"./models/\"+ str(model_no))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365187 training set records, 73039 validation set records.\n",
      "[2024_05_10-07:48:38] Training set: Filtered out 0 of 365187 (0.0%) records of lengths exceeding 40.\n",
      "[2024_05_10-07:48:39] Validation set: Filtered out 0 of 73039 (0.0%) records of lengths exceeding 40.\n",
      "[2024_05_10-07:48:40] Training the entire fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krzysztof\\anaconda3\\envs\\pbert\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer GlobalAttention has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krzysztof\\anaconda3\\envs\\pbert\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "5707/5707 [==============================] - 199s 33ms/step - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 2/40\n",
      "5707/5707 [==============================] - 209s 37ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 3/40\n",
      "5707/5707 [==============================] - 307s 54ms/step - loss: 9.7335e-04 - val_loss: 0.0022\n",
      "Epoch 4/40\n",
      "5707/5707 [==============================] - 180s 32ms/step - loss: 4.1454e-04 - val_loss: 0.0026\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 5/40\n",
      "5707/5707 [==============================] - 180s 32ms/step - loss: 1.6850e-04 - val_loss: 0.0032\n",
      "Epoch 6/40\n",
      "5707/5707 [==============================] - 181s 32ms/step - loss: 1.0583e-04 - val_loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n",
      "C:\\Users\\Krzysztof\\anaconda3\\envs\\pbert\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365194 training set records, 73032 validation set records.\n",
      "[2024_05_10-08:10:11] Training set: Filtered out 0 of 365194 (0.0%) records of lengths exceeding 40.\n",
      "[2024_05_10-08:10:13] Validation set: Filtered out 0 of 73032 (0.0%) records of lengths exceeding 40.\n",
      "[2024_05_10-08:10:14] Training the entire fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krzysztof\\anaconda3\\envs\\pbert\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer GlobalAttention has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krzysztof\\anaconda3\\envs\\pbert\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer GlobalAttention has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "5707/5707 [==============================] - 290s 49ms/step - loss: 0.0075 - val_loss: 0.0034\n",
      "Epoch 2/40\n",
      "5707/5707 [==============================] - 182s 32ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 3/40\n",
      "5707/5707 [==============================] - 180s 31ms/step - loss: 0.0012 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 4/40\n",
      "5707/5707 [==============================] - 173s 30ms/step - loss: 3.0028e-04 - val_loss: 0.0032\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 5/40\n",
      "5707/5707 [==============================] - 170s 30ms/step - loss: 6.1444e-05 - val_loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n",
      "C:\\Users\\Krzysztof\\anaconda3\\envs\\pbert\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/6\\assets\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
